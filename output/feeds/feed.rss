<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0"><channel><title>Longest Path Search</title><link>https://guille.site/</link><description></description><lastBuildDate>Wed, 17 Mar 2021 00:00:00 -0700</lastBuildDate><item><title>A note on "Optimal Design of Controlled Environment Agricultural Systems (...)"</title><link>https://guille.site/note-optimal-env-systems.html</link><description>&lt;p&gt;This is just a basic note on Cetegen and Stuber's paper (apologies for the paywall) published a few days
ago, &lt;a href="https://www.sciencedirect.com/science/article/pii/S0098135421000636"&gt;&lt;em&gt;Optimal Design of Controlled Environment Agricultural Systems Under Market Uncertainty&lt;/em&gt;&lt;/a&gt;. This post "simplifies" problem (4) from a bilevel optimization problem to a single (convex) optimization problem which can be readily …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Guillermo Angeris</dc:creator><pubDate>Wed, 17 Mar 2021 00:00:00 -0700</pubDate><guid isPermaLink="false">tag:guille.site,2021-03-17:/note-optimal-env-systems.html</guid><category>optimization</category><category>math</category><category>convex</category><category>note</category></item><item><title>Comparisons and information theory: why the worst-case complexity of sorting is n log n</title><link>https://guille.site/sorting-bounds.html</link><description>&lt;p&gt;In this post, we'll talk a bit about the usual proofs about the
worst-case query complexity of sorting (at least, in the deterministic case) and then
use a beautiful (and surprisingly simple!) tool from computational lower bounds to give a very general argument about the construction &lt;/p&gt;
&lt;h2&gt;The usual approach&lt;/h2&gt;
&lt;p&gt;There …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Guillermo Angeris</dc:creator><pubDate>Fri, 19 Jun 2020 00:00:00 -0700</pubDate><guid isPermaLink="false">tag:guille.site,2020-06-19:/sorting-bounds.html</guid><category>math</category><category>math</category><category>information-theory</category><category>statistics</category></item><item><title>The S-procedure and small covering ellipsoids</title><link>https://guille.site/covering-ellipsoid.html</link><description>&lt;p&gt;&lt;em&gt;Note:&lt;/em&gt; This post was inspired by &lt;a href="https://msl.stanford.edu/people/kunal-shah"&gt;Kunal Shah&lt;/a&gt;'s question that came up at some point during one of our meetings: is there an efficient way of finding an ellipsoid which covers the intersections and unions of a bunch of other ellipsoids?&lt;/p&gt;
&lt;p&gt;While this question has been explored &lt;a href="https://pdfs.semanticscholar.org/ab38/565f7957f7ee4980663324b5820b0a018de2.pdf"&gt;somewhat&lt;/a&gt; &lt;a href="http://www.optimization-online.org/DB_FILE/2018/07/6719.pdf"&gt;extensively …&lt;/a&gt;&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Guillermo Angeris</dc:creator><pubDate>Wed, 05 Jun 2019 00:00:00 -0700</pubDate><guid isPermaLink="false">tag:guille.site,2019-06-05:/covering-ellipsoid.html</guid><category>convex-optimization</category><category>math</category><category>control-theory</category><category>S-procedure</category></item><item><title>Physics, optimization, and impossibility</title><link>https://guille.site/physics-impossibility-results.html</link><description>&lt;p&gt;&lt;em&gt;Note:&lt;/em&gt; this post is based on the results of &lt;a href="https://arxiv.org/abs/1811.12936"&gt;this arXiv paper&lt;/a&gt; which I've been working on with Stephen Boyd and Jelena Vuckovic.&lt;/p&gt;
&lt;p&gt;The main result of the above paper is kind of weird: essentially, it turns out that you can say what devices are physically &lt;em&gt;impossible&lt;/em&gt; by phrasing certain …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Guillermo Angeris</dc:creator><pubDate>Mon, 17 Dec 2018 00:00:00 -0800</pubDate><guid isPermaLink="false">tag:guille.site,2018-12-17:/physics-impossibility-results.html</guid><category>physics</category><category>optimization</category><category>math</category><category>physics</category><category>research</category></item><item><title>Markov processes and the second law</title><link>https://guille.site/second-law-markov.html</link><description>&lt;p&gt;&lt;em&gt;Note:&lt;/em&gt; This is another one of those "quick" posts about a topic I've found to be fascinating, but which is almost never discussed.&lt;/p&gt;
&lt;p&gt;Physics has this nice little law called the &lt;a href="https://en.wikipedia.org/wiki/Second_law_of_thermodynamics"&gt;second law of thermodynamics&lt;/a&gt;, which governs every physical thermodynamical system in question. The second law is usually phrased as …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Guillermo Angeris</dc:creator><pubDate>Thu, 13 Sep 2018 00:00:00 -0700</pubDate><guid isPermaLink="false">tag:guille.site,2018-09-13:/second-law-markov.html</guid><category>math</category><category>statistics</category><category>math</category><category>information-theory</category><category>physics</category><category>quick-post</category></item><item><title>Machine learning, information, and tail bounds</title><link>https://guille.site/ml-information-bounds.html</link><description>&lt;p&gt;Usually, in explaining the connection between information theory and machine learning, I would begin by writing down the definition of entropy and deriving some useful results about it, and then come back to tell you that you can look at ML as an information problem, where nature picks some parameters …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Guillermo Angeris</dc:creator><pubDate>Tue, 04 Sep 2018 00:00:00 -0700</pubDate><guid isPermaLink="false">tag:guille.site,2018-09-04:/ml-information-bounds.html</guid><category>machine-learning</category><category>statistics</category><category>math</category><category>information-theory</category></item><item><title>PCA as a convex optimization problem</title><link>https://guille.site/pca-convex.html</link><description>&lt;p&gt;It's been a while since I last posted (my posting has been less once every two weeks and more like once every two months), but here's a post I've been sitting on for a while that I never got around to finishing. As per &lt;a href="https://rachelbythebay.com/w/2018/03/13/write/"&gt;rachelbythebay's advice&lt;/a&gt;, I decided to just …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Guillermo Angeris</dc:creator><pubDate>Wed, 16 May 2018 00:00:00 -0700</pubDate><guid isPermaLink="false">tag:guille.site,2018-05-16:/pca-convex.html</guid><category>convex-optimization</category><category>math</category><category>pca</category><category>non-convex</category><category>convex</category></item><item><title>Fast shortest paths for time-varying graphs (Part 4/?)</title><link>https://guille.site/path-optimization-thoughts4.html</link><description>&lt;p&gt;This is the fourth post in a series of posts describing an approach to doing path-planning in real-time on a small, embedded compute board. This is yet another relatively standalone post which mostly describes how to generate a (starting) path used in the &lt;a href="/path-optimization-thoughts2.html"&gt;second&lt;/a&gt; and &lt;a href="/path-optimization-thoughts.html"&gt;first&lt;/a&gt; posts to generate a …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Guillermo Angeris</dc:creator><pubDate>Sat, 17 Mar 2018 00:00:00 -0700</pubDate><guid isPermaLink="false">tag:guille.site,2018-03-17:/path-optimization-thoughts4.html</guid><category>auvsi-competition</category><category>control-theory</category><category>math</category><category>non-convex</category><category>path-planning</category><category>graph-theory</category><category>auvsi</category></item><item><title>Proximal gradient for SVM</title><link>https://guille.site/svm-prox.html</link><description>&lt;p&gt;For a class that's currently being written (&lt;em&gt;ahem&lt;/em&gt;, EE104), Prof. Boyd posed an interesting problem of writing a (relatively general, but ideally simple) proximal-gradient optimizer. The idea is that would act as a black-box way for students to plug in machine learning models of a specific form and have the …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Guillermo Angeris</dc:creator><pubDate>Fri, 22 Dec 2017 00:00:00 -0800</pubDate><guid isPermaLink="false">tag:guille.site,2017-12-22:/svm-prox.html</guid><category>optimization-methods</category><category>machine-learning</category><category>math</category><category>optimization-methods</category></item><item><title>Optimizers, momentum, and cooling schedules (Part 2/?)</title><link>https://guille.site/path-optimization-thoughts2.html</link><description>&lt;p&gt;This is the second post in a series of posts describing an initial approach to doing path-planning in real-time on a small, embedded compute board. For the first in the series which describes the energy function used below, see the &lt;a href="/path-optimization-thoughts.html"&gt;first post&lt;/a&gt;.&lt;/p&gt;
&lt;h2&gt;Quick recap&lt;/h2&gt;
&lt;p&gt;Anyways, we left off on the …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Guillermo Angeris</dc:creator><pubDate>Sun, 22 Oct 2017 00:00:00 -0700</pubDate><guid isPermaLink="false">tag:guille.site,2017-10-22:/path-optimization-thoughts2.html</guid><category>auvsi-competition</category><category>control-theory</category><category>math</category><category>non-convex</category><category>path-planning</category><category>auvsi</category></item><item><title>Some thoughts on global path optimization (Part 1/?)</title><link>https://guille.site/path-optimization-thoughts.html</link><description>&lt;p&gt;I usually see path planning in some shape or form usually solved as a Bellman update, Dynamic Programming-style problem, where the given control is asymptotically stable and optimal; in general, this seems to work quite well, but when we have so much computational power available now-a-days, I do wonder if …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Guillermo Angeris</dc:creator><pubDate>Tue, 17 Oct 2017 00:00:00 -0700</pubDate><guid isPermaLink="false">tag:guille.site,2017-10-17:/path-optimization-thoughts.html</guid><category>auvsi-competition</category><category>control-theory</category><category>math</category><category>non-convex</category><category>path-planning</category><category>auvsi</category></item><item><title>Least-squares and image processing</title><link>https://guille.site/ls-images.html</link><description>&lt;p&gt;Least squares is one of those things that seems relatively simple once you first look at it (perhaps also because most linear algebra texts relegate it to nothing more than a page or two on their textbooks), but has surprisingly powerful implications that are quite nice, and, most importantly, that …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Guillermo Angeris</dc:creator><pubDate>Tue, 19 Sep 2017 00:00:00 -0700</pubDate><guid isPermaLink="false">tag:guille.site,2017-09-19:/ls-images.html</guid><category>least-squares</category><category>math</category><category>least-squares</category><category>image-processing</category></item><item><title>PID as least squares</title><link>https://guille.site/pid-ls.html</link><description>&lt;p&gt;I want to say this is a folk theorem (borrowing terminology from game theory) in that everyone who does optimal control theory knows about this stuff, probably,&lt;sup id="fnref:people"&gt;&lt;a class="footnote-ref" href="#fn:people"&gt;1&lt;/a&gt;&lt;/sup&gt; but I haven't really seen it stated explicitly anywhere. If anyone does indeed work on optimal control, I'd love to know your …&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Guillermo Angeris</dc:creator><pubDate>Wed, 13 Sep 2017 00:00:00 -0700</pubDate><guid isPermaLink="false">tag:guille.site,2017-09-13:/pid-ls.html</guid><category>least-squares</category><category>control-theory</category><category>math</category><category>least-squares</category></item><item><title>This blog is a lie</title><link>https://guille.site/blog-lie.html</link><description>&lt;p&gt;(Maybe.)&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Guillermo Angeris</dc:creator><pubDate>Tue, 12 Sep 2017 00:00:00 -0700</pubDate><guid isPermaLink="false">tag:guille.site,2017-09-12:/blog-lie.html</guid><category>random</category></item></channel></rss>