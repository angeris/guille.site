<!DOCTYPE html>
<html lang="en">
<head>
    <title>Optimizers, momentum, and cooling schedules (Part 2/?)</title>
    
    <link rel="stylesheet" href="/theme/css/main.css">
    <link href="https://fonts.googleapis.com/css?family=Raleway:100,300,500" rel="stylesheet">

    <script type="text/x-mathjax-config">
        MathJax.Hub.Config({
            tex2jax: {
                inlineMath: [ ['$','$'], ['\\(','\\)'] ]
            },
        });
    </script>
    
    <script type="text/javascript" async
    src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.2/MathJax.js?config=TeX-MML-AM_CHTML">
    </script>
    
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">    	

</head>
<body>
    <div class="container">
<div class="row">
    <div class="col-md-8">
        <h2><a href="/">&larr; Home</a></h2>
        <h1>Optimizers, momentum, and cooling schedules (Part 2/?)</h1>
        <p>Category: <a href="/category/auvsi-competition.html">auvsi-competition</a></p>
        <p><label>Posted <strong>October 21, 2017</strong></label></p>
        <p>This is the second post in a series of posts describing an intial approach to doing path-planning in real time on a small, embedded compute board. For the first in the series which describes the energy function used below, see the <a href="/path-optimization-thoughts.html">first post</a>.</p>
<h2>Quick recap</h2>
<p>Anyways, we left off on the idea that we now have a function which we wish to optimize, along with a sequence of constants $C$ which tends to a given solution—in particular, and perhaps most importantly, we only care about the solution in the limit $C\to\infty$.</p>
<p>As before, though, we can't just optimize the function
$$
\mathcal{L}(x; c, R, C) = \sum_{i}\left[\sum_j\phi\left(C\left(\frac{\lVert x_i - c_j \lVert_2^2}{R_j^2} - 1\right)\right) + \eta \lVert x_i - x_{i+1}\lVert_2^2\right]
$$</p>
<p>over some large $C$, since we've noted that the objective becomes almost-everywhere flat in the limit<sup id="fnref-measure-theory"><a class="footnote-ref" href="#fn-measure-theory">1</a></sup> and thus becomes very difficult to optimize using typical methods. Instead, we optimize over the sequence of functions, for $C_k \to \infty$,</p>
<p>$$
x^{(k)} = \min_x\mathcal{L}(x; c, R, C_k) 
$$</p>
<p>picking only</p>
<p>$$
x^* = \lim_{k\to\infty} x^{(k)}
$$</p>
<p>as our final trajectory. The goal of this post is to explore some methods for optimizing this function in the constrained, embedded environment which we'll be using for the competition.</p>
<h2>Gradient descent</h2>
<p>I'll do a quick introduction to gradient descent since there are <a href="https://medium.com/ai-society/hello-gradient-descent-ef74434bdfa5">plenty</a> of <a href="https://machinelearningmastery.com/gradient-descent-for-machine-learning/">posts</a> on <a href="https://www.quora.com/What-is-an-intuitive-explanation-of-gradient-descent">this</a> <a href="http://homes.soic.indiana.edu/classes/spring2012/csci/b553-hauserk/gradient_descent.pdf">method</a>, many of which I suspect are much better than anything I'll ever write.</p>
<p>Anyways, the simple idea (or another perspective on it) is that, if we want to find the minimum of a function $V$, then we can think about the function as a potential for a particle, whose position we call $x$, and then just run Newton's equation forward in time!</p>
<p>$$
m\ddot x = -\nabla V(x)
$$</p>
<p>where $\ddot x = \frac{d^2x}{dt^2}$ (this is just a rewriting of $F=ma=m\ddot x$, where our force is conservative).  You may notice a problem with this idea: well, if we land in a well, we'll continue oscillating... that is, there's literally no friction to stop us from just continuing past the minimum. So, let's add this in as a force proportional to the velocity (but pointing in the opposite direction), with friction coefficient $\mu&gt;0$:</p>
<p>$$
m\ddot x = -\nabla V(x) - \mu \dot x.
$$</p>
<p>Now, here I'll note we can do two things: one, we can keep the former term containing acceleration (i.e. momentum), accepting that we could possibly overshoot our minimum (because, say, we're going 'too fast') but then later 'come back' to it (this is known as gradient descent with momentum),<sup id="fnref-momentum"><a class="footnote-ref" href="#fn-momentum">2</a></sup> or, if we never want to overshoot it (but allow for the possibility that we may always be too slow in getting there in the first place) we can just send our momentum term to zero by sending $m \to 0$. I'll take the latter approach for now, but we'll consider the former case, soon.</p>
<p>Anyways, sending $m\to 0$ corresponds to having a ball slowly rolling down an extremely sticky hill, stopping only at a local minimum, that is:</p>
<p>$$
\mu\dot x + \nabla V(x) = 0
$$</p>
<p>or, in other words:</p>
<p>$$
\dot x = -\frac{1}{\mu}\nabla V(x).
$$</p>
<p>Discretizing this equation by noting that, by definition of the derivative, we have</p>
<p>$$
\dot x(t_{i+1}) \approx \frac{x_{i+1} - x_i}{h}
$$</p>
<p>then gives us (by plugging this into the above)</p>
<p>$$
\frac{x_{i+1} - x_i}{h} = -\frac{1}{\mu}\nabla V(x),
$$</p>
<p>or, after rearranging (and setting $\mu=1$, since we can control $h$ however we like, say by defining $h := \frac{h}{\mu}$)</p>
<p>$$
x_{i+1} = x_i - h\nabla V(x).
$$</p>
<p>In other words, gradient descent corresponds to the discretization of Newton's equations in the <em>overdamped</em> limit (e.g. in the limit of small mass and large friction).</p>
<p>This method is great because (a) we know it converges with probability 1 (as was relatively recently proven <a href="https://arxiv.org/abs/1602.04915">here</a>) for arbitrary, somewhat nice functions and (b) because it <em>works</em>. That being said, it's slow; for example, in the previous post, we saw that it converged after 5000 iterations (which, to be fair, takes about 20 seconds on my machine, but still).</p>
<p>A simple improvement (where we don't throw $m\to 0$) yields a significant speed up! Of course, at the cost of having to deal with more hyperparameters, but that's okay: we're big kids now, and we can deal with more than one hyperparameter in our problems.</p>
<h2>Gradient descent with momentum</h2>
<p>The next idea is to, instead of taking $m\to 0$, just write out the full discretization scheme. To make our lives easier, we rewrite $v(t) \equiv \dot x(t)$ to be our velocity, this gives us a simple rewriting of the form:</p>
<p>$$
\begin{align}
m\dot v &amp;= -\nabla V(x) - \mu v\\
\dot x(t) &amp;= v(t)
\end{align}
$$</p>
<p>discretizing the second equation with some step-size $h'$ (as above) we get</p>
<p>$$
x_{t+1} = x_t + h'v_{t+1}
$$</p>
<p>where the former equation is, when discretized with some step size $h$</p>
<p>$$
m\frac{v_{t+1} - v_t}{h} = -\nabla V(x_t) - \mu v_t
$$</p>
<p>or after rearranging, and defining $\gamma \equiv \frac{h}{m}$ (which we can make as small as we'd like)</p>
<p>$$
\begin{align}
v_{t+1} &amp;= -\gamma \nabla V(x_t) + (1-\mu \gamma) v_t\\
x_{t+1} &amp;= x_t + h'v_{t+1}
\end{align}
$$</p>
<p>usually we take $h' = 1$, and, to prevent $v_t$ from having weird behaviour, we require that $1-\mu\gamma &gt; 0$, i.e. that $\gamma &lt; \frac{1}{\mu}$.<sup id="fnref-oscillations"><a class="footnote-ref" href="#fn-oscillations">3</a></sup> If we call $\beta \equiv 1 - \mu\gamma$ and therefore have that $0 &lt; \beta  &lt; 1$ then we obtain the classical momentum for gradient descent</p>
<p>$$
\begin{align}
v_{t+1} &amp;= -\gamma \nabla V(x_t) + \beta v_t\\
x_{t+1} &amp;= x_t + v_{t+1}
\end{align}
$$</p>
<p>which is what we needed! Well, close to what we needed, really.</p>
<p>Anyways, just to give some perspective on the speed up: using momentum, the optimization problem took around 300 iterations to converge, more than 10 times less than the original given above. I'll give a picture of this soon, but I'm missing one more slight detail.</p>
<h2>Cooling schemes</h2>
<p>Imagine we want to optimize some function $\ell(\cdot)$ that is, in general, extremely hard to solve. If we're lucky, we may be able to do the next best thing: take a series of functions parametrized by, say, $C$, such that $\ell_C(\cdot) \to \ell(\cdot)$ as $C\to\infty$,<sup id="fnref-approaches"><a class="footnote-ref" href="#fn-approaches">4</a></sup> <em>and</em> where the problem is simple to solve for $C_{k+1}$, given the solution for $C_k$.</p>
<!-- <video controls>
    <source src="/images/path-optimization-1/path_optimization.mp4" type="video/mp4">
</video> -->

<p>As before, some code (with more details and implementation) can be found in the <a href="https://github.com/StanfordAIR/optimization-sandbox">StanfordAIR Github repo</a>.</p>
<!-- Footnotes -->

<div class="footnote">
<hr>
<ol>
<li id="fn-measure-theory">
<p>This is, indeed, a technical term, but it's also quite suggestive of what really happens.&#160;<a class="footnote-backref" href="#fnref-measure-theory" title="Jump back to footnote 1 in the text">&#8617;</a></p>
</li>
<li id="fn-momentum">
<p>Of course, there are many reasons why we'll want momentum, but those will come soon.&#160;<a class="footnote-backref" href="#fnref-momentum" title="Jump back to footnote 2 in the text">&#8617;</a></p>
</li>
<li id="fn-oscillations">
<p>Consider $V(x) = 0$, with some initial condition, $v_0 &gt; 0$, say, then we'll have
$$
v_t = -k v_{t-1}
$$
for some $k = \mu\gamma - 1&gt;0$. Solving this yields $v_{t} = (-1)^tk^t v_{0}$. This is weird, because it means that our velocity will change directions every iteration even though there's no potential! This is definitely not expected (nor desirable) behaviour.&#160;<a class="footnote-backref" href="#fnref-oscillations" title="Jump back to footnote 3 in the text">&#8617;</a></p>
</li>
<li id="fn-approaches">
<p>In some sense. Say: in the square error, or something of the like.&#160;<a class="footnote-backref" href="#fnref-approaches" title="Jump back to footnote 4 in the text">&#8617;</a></p>
</li>
</ol>
</div>
        <hr>
        <div class="socials">
            <li>Got any questions?</li>
            <li><a href="https://twitter.com/intent/tweet?screen_name=guilleangeris" class="twitter-mention-button" data-size="large" data-show-count="false">Tweet to @guilleangeris</a><script async src="//platform.twitter.com/widgets.js" charset="utf-8"></script></li>
        </div>
    </div>
</div>
    </div>
</body>
<footer>
    Made with <a href="https://blog.getpelican.com">🐍</a> and hosted on <a href="https://neocities.org">neocities.org</a>.
</footer>
<script>
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

    ga('create', 'UA-73543332-2', 'auto');
    ga('send', 'pageview');
</script>
</html>